{"title":"Alberta In-situ Oilsands Production Analysis using Python - Part II","markdown":{"yaml":{"title":"Alberta In-situ Oilsands Production Analysis using Python - Part II","subtitle":"Preparing a tidy dataset for data analysis and visualization","author":"Farshad Tabasinejad","date":"2023-03-04","toc":true,"draft":false,"categories":["python","pandas","data analysis","data visualization"],"image":"top_ten_largest_ever.png","execute":{"cache":false,"output":true},"format":{"html":{"code-fold":false,"code-tools":false,"code-overflow":"wrap","code-block-bg":true,"code-block-border-left":"#31BAE9","code-copy":"hover","highlight":"zenburn"}},"jupyter":"python3"},"headingText":"Disclaimer","containsRefs":false,"markdown":"\n\n\nThis blog post is for educational purposes only. Any commercial use of the information provided in this blog post is prohibited. For more information about the AER copyright and permission to reproduce, please visit [AER Copyright and Disclaimer](https://www.aer.ca/copyright-disclaimer).\nThe author is not responsible for any damage or loss caused by the use of the information provided in this blog post. \n\n# Introduction\n\nThis blog post focuses on analyzing the bitumen production data from in-situ oilsands projects in Alberta. Alberta Energy Regulator (AER) lists the monthly injection and production data for all in-situ oilsands projects in Alberta on its website [Alberta Energy Regulator](https://www.aer.ca/). The data is available in several spreadsheets and can be downloaded from [ST53: Alberta In Situ Oil Sands Production Summary](https://www.aer.ca/providing-information/data-and-reports/statistical-reports/st53). The annual data are reported in separate files in .xls format. Each file has 6 different sheets with the following information: bitumen production, water usage, steam injection, well count, steam-to-oil ratio (SOR), and water-to-oil ratio (WSR).\n\nIn the previous post [Downloading Alberta Oilsands Production Data using Python](), I have shown how to download the data using python. In this post we create a tidy bitumen dataset for data analysis and visualization.\n\n# Loading the Data\n\nAll files are stored in the current local directory. We use the `glob` module to list all `.xls` files in the directory and then use `pandas` to read the data into a `DataFrame`. The `xlrd` is used as an engine in pandas to read the `.xls` files. The `numpy` module is used to perform mathematical operations on the data. The `warnings` module is used to suppress the warnings.\n\n```{python}\nimport glob\nimport pandas as pd\nimport numpy as np\nimport xlrd\nimport warnings\nwarnings.filterwarnings('ignore')\n```\n\nThe `glob` module is used in this code to create a list of file paths for all the .xls files in the current directory.\n\n```{python}\nxls_files = glob.glob('*.xls')\nxls_files\n```\n\n# Analyzing the 2010 bitumen production data\nThis section describes the steps for creating a tidy dataset for bitumen production using the 2010 data.\n\n## Reading the first file\n\nTo start, we read the data from the `ST53_2010.xls` file using the `read_excel` function from the pandas library. We set the `sheet_name` argument to `None` to read all the sheets in the file. We also use the `skiprows` argument to skip the first three rows of each sheet. Finally, we use the `keys()` method to print the names of the sheets in the file.\n\n```{python}\nsheets = pd.read_excel(xls_files[0], sheet_name = None, skiprows = 3)\nprint(f'sheet names: {sheets.keys()}')\n```\n\n## Reading the BITUMEN sheet\n\n```{python}\n# read the BITUMEN sheet\nbitumen_2010 = sheets['BITUMEN']\n```\n\nThe `info` method is used to print the column names and data types of each column in the DataFrame.\n\n```{python}\nbitumen_2010.info()\n``` \n\nThe `head` method is used to display the first 5 rows of the `DataFrame`.\n\n```{python}\nbitumen_2010.head()\n```\n\nThe `tail` method is used to print the last 20 rows of the `DataFrame`.\n\n```{python}\nbitumen_2010.tail(20)\n``` \n\nSince the number of producers in the file can vary, we cannot rely on a fixed index number to subset the dataset. However, the last row of the dataset always contains a summary of the total production, which is identified by the cell value of __Total__ in the `Recovery Method` column. Therefore, we can use the index number of the row with __Total__ in the Recovery Method column to subset the dataset and exclude the summary row and any other rows with additional information.\n\n```{python}\n# get the index of the last row using np.where\nlast_row_idx = np.where(bitumen_2010[[\"Recovery Method\"]] == \"Total \")[0][0]\nbitumen_2010 = bitumen_2010.iloc[:last_row_idx, :]\n```\n\nIn addition, we can remove the `Monthly Average` column from the dataset since we will be aggregating the data in our analysis and therefore do not need the monthly averages.\n\n```{python}\nbitumen_2010 = bitumen_2010.drop(columns = ['Monthly Average'])\n```\n\n## Cleaning the Operator column\n\nLet's take a look at the `Operator` column.\n\n```{python}\nbitumen_2010['Operator'].unique()\n```\n\nThe Operator column contains several names that are followed by `(subscripts)`. These additional pieces of information create inconsistencies in the `Operator` column and add unnecessary complexity to the dataset. Since they are not needed for our analysis, we can remove them using the `replace` method.\n\n```{python}\nbitumen_2010['Operator'] = bitumen_2010['Operator'].str.replace(r'\\(.*\\)', '').str.strip()\nbitumen_2010['Operator'].unique()\n```\n\nThe operator names in the dataset may contain inconsistencies where some operators are listed with different names. To make the names consistent, we can create a dictionary with the names to be replaced and the new names. However, it's important to note that the following dictionary may contain additional names that are not in the 2010 dataset. This dictionary was created using data from all the files between 2010 and 2022.\n\n\n```{python}\n# create a dictionary to make Operator names consistent\noperators_dict = {'Athabasca Oil Corporation': 'Athabasca Oil',\n                  'Baytex Energy Ltd.': 'Baytex',\n                  'Blackpearl Resources Inc.': 'BlackPearl',\n                  'BlackPearl Resources Inc.': 'BlackPearl',\n                  'Bonavista Petroleum Ltd.': 'Bonavista',\n                  'Bonavista Energy Corporation': 'Bonavista',\n                  'CNOOC Petroleum North America ULC': 'CNOOC',\n                  'Canadian Natural Resources': 'CNRL',\n                  'Canadian Natural Resources Limited': 'CNRL',\n                  'Canadian Natural Upgrading Limited': 'CNRL',\n                  'Cenovus Energy Inc.': 'Cenovus',\n                  'Cenovus FCCL Ltd.': 'Cenovus',\n                  'ConocoPhillips Canada Resources Corp.': 'ConocoPhillips',\n                  'ConocoPhillips Canada Limited': 'ConocoPhillips',\n                  'Devon Canada Corporation': 'Devon',\n                  'Devon NEC Corporation': 'Devon',\n                  'ExxonMobil Canada Ltd.': 'Imperial',\n                  'Greenfire Hangingstone Operating Corporation': 'Greenfire',\n                  'Greenfire Resources Operating Corporation': 'Greenfire',\n                  'Husky Oil Operations Limited' : 'Husky',\n                  'Husky Oil Operations Ltd.' : 'Husky',\n                  'Imperial Oil Resources': 'Imperial',\n                  'Imperial Oil Resources Limited': 'Imperial',\n                  'Islander Oil & Gas Inc.': 'Islander',\n                  'Koch Exploration Canada G/P Ltd.': 'Koch',\n                  'Koch Oil Sands Operating ULC': 'Koch',\n                  'MEG Energy Corp.': 'MEG',\n                  'Meg Energy Corp.': 'MEG',\n                  'Murphy Oil Canada': 'Murphy',\n                  'Murphy Oil Company Ltd.': 'Murphy',\n                  'Nexen Energy ULC': 'Nexen',\n                  'Nexen Inc.': 'Nexen',\n                  'Obsidian Energy Ltd.': 'Obsidian',\n                  'OSUM Oil Sands Corp.': 'OSUM',\n                  'Osum Production Corp.': 'OSUM',\n                  'Pengrowth Corporation': 'Pengrowth',\n                  'Pengrowth Energy Corporation': 'Pengrowth',\n                  'Penn West Energy Trust': 'Penn West',\n                  'Penn West Petroleum Ltd.': 'Penn West',\n                  'Perpetual Energy Inc.': 'Perpetual',\n                  'Perpetual Energy Operating Corp.': 'Perpetual',\n                  'Perpetual Operating Corp.': 'Perpetual',\n                  'PetroChina Canada Ltd.': 'PetroChina',\n                  'Petrochina Canada Ltd.': 'PetroChina',\n                  'Strathcona Resources Ltd.': 'Strathcona',\n                  'Shell Canada Energy': 'Shell',\n                  'Shell Canada Limited': 'Shell',\n                  'Spur Petroleum Ltd.': 'Spur',\n                  'Spur Resources Ltd.': 'Spur',\n                  'Suncor Energy Inc.': 'Suncor',\n                  'Woodcote Oil & Gas Inc.': 'Woodcote',\n                  'Woodcote Oil Corp.': 'Woodcote'\n                  }\n```\n\n\n```{python}\n# replace the names in the Operator column\nbitumen_2010['Operator'] = bitumen_2010['Operator'].replace(operators_dict)\nbitumen_2010['Operator'].unique()\n```\n\nIt should be noted that there have been a number of acquisitions and mergers in the oil and gas industry in recent years, and this can lead to inconsistencies in the naming of operators across different years. However, for the sake of simplicity, we will ignore these changes and assume that operator names remain consistent across all years.\n\n## Simplifiying the Area column\n\nTo simplify the `Area` column, we can replace the values `Peace River Area 1` and `Peace River Area 2` with a single value `Peace River`. This is done to aggregate the production data for the Peace River area.\n\n\n```{python}\nbitumen_2010['Area'] = bitumen_2010['Area'].replace({'Peace River Area 1': 'Peace River', 'Peace River Area 2': 'Peace River'}) \nbitumen_2010['Area'].unique()\n```\n\nThere is only one row with an `Area` value of `Athabasca, Cold Lake`. To make it consistent with the other rows, we can change it to `Cold Lake`.\n\n```{python}\nbitumen_2010['Area'] = bitumen_2010['Area'].replace({'Athabasca, Cold Lake': 'Cold Lake'})\n```\n\nWe also add a `Year` column to the dataframe.\n\n```{python}\nbitumen_2010['Year'] = int(xls_files[0].split('_')[-1].split('-')[0])\nbitumen_2010['Year'].unique()\n```\n\n# Creating a single tidy dataset for bitumen production for all years\n\nWe can combine all the previous steps to create a function that generates a tidy dataset for the bitumen analysis. The function takes the following arguments:\n\n- `df`: a dataframe for a given year\n- `operators_dict`: a dictionary with the names to be replaced and the new names\n- `xls_file`: the name of the excel file for a given year\n\n```{python}\n# define a function to create a tidy dataset for bitumen production\ndef create_tidy_bitumen(df, operators_dict, xls_file):\n    last_row_idx = np.where(df[[\"Recovery Method\"]] == \"Total \")[0][0]\n    df = df.iloc[:last_row_idx, :]\n    df = (df\n            .drop(columns = ['Monthly Average'])\n            .dropna(subset = ['Operator'])\n            .assign(Operator = lambda x: x.Operator.str.split('(').str[0].str.strip())\n            .assign(Operator = lambda x: x.Operator.str.replace('  ', ' '))\n            .replace({'Operator': operators_dict})\n            .assign(Year = int(xls_file.split('_')[-1].split('-')[0]))\n            .assign(Area = lambda x: x.Area.replace({'Peace River Area 1': 'Peace River', 'Peace River Area 2': 'Peace River'}))\n    )\n    return df\n```\n\nTo generate a tidy dataset for bitumen production for all years, we can use the previously defined function to create tidy datasets for each year and then use a for loop to iterate through all the .xls files. For each year, we generate a tidy dataset using the function and append it to the `bitumen` dataframe using the `df.append()` method.\n\n```{python}\n# create a tidy dataset for bitumen production for all years\nbitumen = pd.DataFrame()\nfor xls_file in xls_files:\n    df = pd.read_excel(xls_file, sheet_name = None, skiprows = 3)\n    bitumen = bitumen.append(create_tidy_bitumen(df['BITUMEN'], operators_dict, xls_file))\n```\n\nLet's check the `Year` column to make sure that we have data for all years.\n\n```{python}\nbitumen['Year'].unique()\n```\n\n# Saving the dataset\n\nWe save the dataset as a csv file in the current local folder for future use.\n\n```{python}\nbitumen.to_csv('bitumen.csv', index = False)\n```"},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":false,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"jupyter"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":false,"code-overflow":"wrap","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../../styles.css"],"toc":true,"output-file":"index.html"},"language":{},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.2.335","theme":{"light":["Yeti","../../../theme.scss"]},"title-block-banner":false,"title":"Alberta In-situ Oilsands Production Analysis using Python - Part II","subtitle":"Preparing a tidy dataset for data analysis and visualization","author":"Farshad Tabasinejad","date":"2023-03-04","draft":false,"categories":["python","pandas","data analysis","data visualization"],"image":"top_ten_largest_ever.png","jupyter":"python3","code-block-bg":true,"code-block-border-left":"#31BAE9","code-copy":"hover","highlight":"zenburn"},"extensions":{"book":{"multiFile":true}}}}}